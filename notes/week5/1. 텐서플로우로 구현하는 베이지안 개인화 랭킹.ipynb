{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public AI</b></i>\n",
    "<br>\n",
    "\n",
    "# 텐서플로우로 구현하는 베이지안 개인화 랭킹\n",
    "\n",
    "이전 주차에 우리는 텐서플로우로 심층신경망을 구현하는 방법을 배웠습니다. 그리고 3주차에서는 Matrix Factorization하는 방법으로 Bayesian Personalized Ranking을 이용하여 고객에 대한 Embedding 정보, 아이템에 대한 Embedding 정보를 획득하는 방법을 배웠었지요. 이번 시간에는 이전에 배웠던 BPR 알고리즘을 텐서플로우로 구현하는 프로젝트를 통해 텐서플로우의 동작을 더욱 잘 이해해 봅시다.\n",
    "\n",
    "### _Objective_\n",
    "1. **BPR을 텐서플로우로 구현하기** : Tensorflow로 Bayesian Personalized Ranking을 구성하는 방법을 배워봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Embedding\n",
    "np.set_printoptions(5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[ 데이터 셋 : MovieLens 100K\\]\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_URL = \"https://pai-datasets.s3.ap-northeast-2.amazonaws.com/recommender_systems/movielens_100k/datasets/\"\n",
    "\n",
    "# 데이터 가져오기\n",
    "ratings_path = get_file(\"100k_ratings.csv\", ROOT_URL+\"ratings.csv\")\n",
    "movies_path = get_file(\"100k_movies.csv\",ROOT_URL+\"movies.csv\")\n",
    "users_path = get_file(\"100k_users.csv\", ROOT_URL+\"users.csv\")\n",
    "\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "movies_df = pd.read_csv(movies_path)\n",
    "users_df = pd.read_csv(users_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) ratings_df 데이터셋\n",
    "+ user_id : user 식별자\n",
    "+ item_id : 영화(Item) 식별자\n",
    "+ rating : 각 user별 영화의 평가 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings_df의 크기 :  (99991, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27819</th>\n",
       "      <td>358</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86043</th>\n",
       "      <td>806</td>\n",
       "      <td>879</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14316</th>\n",
       "      <td>286</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91233</th>\n",
       "      <td>378</td>\n",
       "      <td>660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28761</th>\n",
       "      <td>311</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "27819      358      529       3\n",
       "86043      806      879       3\n",
       "14316      286       25       3\n",
       "91233      378      660       4\n",
       "28761      311       12       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ratings_df의 크기 : \", ratings_df.shape)\n",
    "\n",
    "# 다섯개 데이터를 Random으로 가져옴\n",
    "ratings_df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) movies_df 데이터셋\n",
    "\n",
    "+ item_id : 영화(item) 식별자\n",
    "+ title : 영화(item) 제목\n",
    "+ year : 영화 개봉 년도\n",
    "+ unknown ~ Western : 영화 장르의 멀티핫인코딩(Multi-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_df의 크기 :  (1681, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1337</td>\n",
       "      <td>Larger Than Life (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1342</td>\n",
       "      <td>Convent, The (Convento, O) (1995)</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>290</td>\n",
       "      <td>Fierce Creatures (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>303</td>\n",
       "      <td>Ulee's Gold (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1676</td>\n",
       "      <td>War at Home, The (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                              title  year  unknown  Action  \\\n",
       "1335     1337            Larger Than Life (1996)  1996        0       0   \n",
       "1340     1342  Convent, The (Convento, O) (1995)  1996        0       0   \n",
       "288       290            Fierce Creatures (1997)  1997        0       0   \n",
       "301       303                 Ulee's Gold (1997)  1997        0       0   \n",
       "1674     1676            War at Home, The (1996)  1996        0       0   \n",
       "\n",
       "      Adventure  Animation  Children  Comedy  Crime  ...  Fantasy  Film-Noir  \\\n",
       "1335          0          0         0       1      0  ...        0          0   \n",
       "1340          0          0         0       0      0  ...        0          0   \n",
       "288           0          0         0       1      0  ...        0          0   \n",
       "301           0          0         0       0      0  ...        0          0   \n",
       "1674          0          0         0       0      0  ...        0          0   \n",
       "\n",
       "      Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "1335       0        0        0        0       0         0    0        0  \n",
       "1340       0        0        0        0       0         0    0        0  \n",
       "288        0        0        0        0       0         0    0        0  \n",
       "301        0        0        0        0       0         0    0        0  \n",
       "1674       0        0        0        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"movies_df의 크기 : \", movies_df.shape)\n",
    "\n",
    "# 5개를 Random으로 가져옴\n",
    "movies_df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) users_df 데이터셋\n",
    "\n",
    "+ user_id : user 식별자\n",
    "+ age : user의 나이 (0\\~4세 :0, 5\\~9세:1, ... )\n",
    "+ gender : user의 성별\n",
    "+ occupation : user의 직업군"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df의 크기 :  (943, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>786</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>266</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>689</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>860</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>retired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age gender     occupation\n",
       "785      786    7      F       engineer\n",
       "94        95    6      M  administrator\n",
       "265      266   12      F  administrator\n",
       "688      689    5      M          other\n",
       "859      860   14      F        retired"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"users_df의 크기 : \", users_df.shape)\n",
    "\n",
    "# 5개를 Random으로 가져옴\n",
    "users_df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Core Sampling을 통해 user_id, item_id 추려내기\n",
    "\n",
    "k=5를 기준으로, 너무나 적게 평가하거나 평가받은 유저 및 영화는 제거하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0회차 데이터 수 : 99,991개\n",
      "1회차 데이터 수 : 99,023개\n",
      "종료\n"
     ]
    }
   ],
   "source": [
    "like_df = ratings_df.copy()\n",
    "\n",
    "threshold = 5\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    prev_total = len(like_df)\n",
    "    print(f\"{count}회차 데이터 수 : {prev_total:,}개\")\n",
    "    \n",
    "    total_user_per_item = (\n",
    "        like_df\n",
    "        .groupby('item_id')['user_id']\n",
    "        .count())\n",
    "    over_item_ids = total_user_per_item[\n",
    "        total_user_per_item>threshold].index\n",
    "    \n",
    "    total_item_per_user = (\n",
    "        like_df\n",
    "        .groupby('user_id')['item_id']\n",
    "        .count())\n",
    "    over_user_ids = total_item_per_user[\n",
    "        total_item_per_user>threshold].index\n",
    "    \n",
    "    like_df = like_df[\n",
    "        (like_df.user_id.isin(over_user_ids))\n",
    "        &(like_df.item_id.isin(over_item_ids))]\n",
    "\n",
    "    if prev_total == len(like_df):\n",
    "        print(\"종료\")\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 평가 기준 설정하기\n",
    "\n",
    "Bayesian Personalized Ranking과 Neural Collaborative Filtering의 성능을 비교해보기 위해 우리는 Hit Ratio를 이용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 평가데이터셋 구성하기\n",
    "\n",
    "우선 Train 데이터셋와 Test 데이터셋을 나누도록 하겠습니다. Test 데이터셋은 각 고객이 평가한 마지막 영화로 두도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = []\n",
    "tests = []\n",
    "for i, group_df in like_df.groupby('user_id'):\n",
    "    # 마지막 직전은 Train_, 미자믹은 test_\n",
    "    train_, test_ = group_df.iloc[:-1], group_df.iloc[-1:]\n",
    "    trains.append(train_)\n",
    "    tests.append(test_)\n",
    "    \n",
    "train_df = pd.concat(trains)\n",
    "test_df = pd.concat(tests)\n",
    "\n",
    "# user_id를 기준으로 정렬된 것을 무작위로 섞음\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 셋의 수 :  98080\n",
      "test 데이터 셋의 수 :  943\n"
     ]
    }
   ],
   "source": [
    "print(\"train 데이터 셋의 수 : \", len(train_df))\n",
    "print(\"test 데이터 셋의 수 : \", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Hit Ratio를 위한 데이터셋 구성하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 시간에는 평가지표를 Hit Ratio를 이용해보도록 하겠습니다.<br>\n",
    "\n",
    "Hit Ratio의 측정방법은 아래와 같습니다.\n",
    "\n",
    "> 고객이 구매한 아이템 1개와 고객이 구매하지 않은 아이템 100개를 가져온 후, 고객이 구매한 아이템 고객이 구매한 아이템이 101개 중 몇번째에 위치하는지를 확인하기. Top-10 Hit Ratio란, 고객이 구매한 아이템이 10번째 안에 들어있는 확률로, 높을수록 보다 정확하게 추천한다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 평가한 영화목록 구성하기\n",
    "itemset_per_user = (\n",
    "    ratings_df\n",
    "    .groupby('user_id')\n",
    "    ['item_id']\n",
    "    .apply(frozenset)\n",
    ")\n",
    "\n",
    "total_items = set(ratings_df.item_id.unique())\n",
    "\n",
    "# 유저가 평가하지 않은 영화목록 구성하기\n",
    "notseen_itemset_per_user = total_items - itemset_per_user\n",
    "notseen_itemset_per_user = notseen_itemset_per_user.apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hit ratio를 계산하기 위해서 우리는 본 영화 1개와 보지 않은 영화 100개를 구성해야 합니다. 그리고 본 영화와 보지 않은 영화 모두 모델로 추론한 후, 선호도 순서대로 정렬 후 본 영화가 10등 안에 들었으면, 모델이 올바르게 추론했다고 평가하고, 들지 않으면 모델이 잘못 추론했다고 평가하는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>not_seen_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87148</th>\n",
       "      <td>390</td>\n",
       "      <td>690</td>\n",
       "      <td>[176, 1415, 1148, 393, 208, 1525, 1204, 1104, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99729</th>\n",
       "      <td>32</td>\n",
       "      <td>408</td>\n",
       "      <td>[1568, 498, 1124, 1378, 1365, 338, 800, 420, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97438</th>\n",
       "      <td>534</td>\n",
       "      <td>508</td>\n",
       "      <td>[833, 963, 513, 1607, 423, 72, 1612, 317, 440,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99644</th>\n",
       "      <td>64</td>\n",
       "      <td>184</td>\n",
       "      <td>[617, 955, 629, 75, 1385, 946, 904, 274, 983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95908</th>\n",
       "      <td>47</td>\n",
       "      <td>262</td>\n",
       "      <td>[610, 201, 141, 377, 457, 1351, 895, 381, 861,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id                                      not_seen_list\n",
       "87148      390      690  [176, 1415, 1148, 393, 208, 1525, 1204, 1104, ...\n",
       "99729       32      408  [1568, 498, 1124, 1378, 1365, 338, 800, 420, 1...\n",
       "97438      534      508  [833, 963, 513, 1607, 423, 72, 1612, 317, 440,...\n",
       "99644       64      184  [617, 955, 629, 75, 1385, 946, 904, 274, 983, ...\n",
       "95908       47      262  [610, 201, 141, 377, 457, 1351, 895, 381, 861,..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_ratio_df = test_df.copy()\n",
    "\n",
    "hit_ratio_df['not_seen_list'] = hit_ratio_df.user_id.apply(\n",
    "    lambda x : random.choices(notseen_itemset_per_user[x],k=100))\n",
    "\n",
    "hit_ratio_df = hit_ratio_df.drop('rating',axis=1)\n",
    "hit_ratio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:03<00:00, 300.44it/s]\n"
     ]
    }
   ],
   "source": [
    "unseen_items = []\n",
    "for user_id, group_df in tqdm(ratings_df.groupby('user_id')):\n",
    "    \n",
    "    sampled_items = (ratings_df\n",
    "                     .loc[~ratings_df.item_id.isin(set(group_df.item_id)), 'item_id']\n",
    "                     .sample(200)\n",
    "                     .drop_duplicates()\n",
    "                     .iloc[:100]\n",
    "                     .tolist()\n",
    "                    )\n",
    "    assert len(sampled_items) == 100\n",
    "    unseen_items.append((user_id, sampled_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_ratio_df = test_df.copy()\n",
    "unseen_df = pd.DataFrame(unseen_items, columns=['user_id', 'not_seen_list'])\n",
    "hit_ratio_df = hit_ratio_df.merge(unseen_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>not_seen_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390</td>\n",
       "      <td>690</td>\n",
       "      <td>[325, 134, 188, 780, 7, 465, 193, 428, 880, 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>408</td>\n",
       "      <td>[426, 748, 203, 596, 1028, 392, 615, 1054, 693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534</td>\n",
       "      <td>508</td>\n",
       "      <td>[430, 8, 401, 229, 56, 272, 523, 26, 152, 781,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>184</td>\n",
       "      <td>[411, 178, 1110, 724, 637, 443, 1017, 483, 250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>262</td>\n",
       "      <td>[483, 237, 502, 239, 427, 520, 514, 191, 245, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id                                      not_seen_list\n",
       "0      390      690  [325, 134, 188, 780, 7, 465, 193, 428, 880, 80...\n",
       "1       32      408  [426, 748, 203, 596, 1028, 392, 615, 1054, 693...\n",
       "2      534      508  [430, 8, 401, 229, 56, 272, 523, 26, 152, 781,...\n",
       "3       64      184  [411, 178, 1110, 724, 637, 443, 1017, 483, 250...\n",
       "4       47      262  [483, 237, 502, 239, 427, 520, 514, 191, 245, ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hit_ratio_df['rating']\n",
    "hit_ratio_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[ 1. Bayesian Personalized Ranking 구성하기 \\]\n",
    "---\n",
    "\n",
    "이전 시간에 배운 Bayesian Personalized Ranking을 텐서플로우로 작성해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Input 구성하기\n",
    "\n",
    "Bayesian Personalized Ranking의 핵심 아이디어는 바로 \n",
    "\n",
    "> 고객이 본 영화는 고객이 보지 않은 영화보다 항상 선호도가 높다\n",
    "\n",
    "입니다. Bayesain Personalized Ranking에서는 고객과 고객이 본 영화, 그리고 고객이 보지 않은 영화 총 3 개의 입력이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "user_id = Input(shape=(), name='user')  # name : user\n",
    "pos_item_id = Input(shape=(), name='positive_item') # name : positive_item \n",
    "neg_item_id = Input(shape=(), name='negative_item') # name : negative_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 임베딩 레이어 구성하기\n",
    "\n",
    "우리가 Bayesian Personalized Ranking에서 해야하는 것은 상호작용 정보를 통해 유저와 아이템에 대한 적절한 임베딩 값을 추론하는 것에 있습니다. 아래와 같이 임베딩 레이어를 생성하도록 하겠습니다.\n",
    "<br>\n",
    "이 때 Item Embedding의 경우, 각 아이템 별 편향 정보(Bias)를 추가하기 위해 Num Factor에 1을 더하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "num_user = ratings_df.user_id.max() + 1\n",
    "num_item = ratings_df.item_id.max() + 1\n",
    "num_factor = 30\n",
    "\n",
    "user_embedding_layer = Embedding(num_user, num_factor, name='user_embedding')\n",
    "item_embedding_layer = Embedding(num_item, num_factor + 1, name='item_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00124,  0.02806,  0.01952,  0.01807, -0.01903,  0.02258,\n",
       "        0.03024, -0.04098, -0.02558, -0.00899, -0.01783, -0.04243,\n",
       "       -0.01648,  0.02209, -0.00038,  0.00113, -0.04222,  0.00695,\n",
       "        0.04144,  0.04491,  0.0142 ,  0.04779,  0.00758,  0.03593,\n",
       "       -0.02769, -0.02174,  0.02441, -0.00663,  0.01617, -0.03903],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_layer.build(input_shape=())\n",
    "W = user_embedding_layer.get_weights()\n",
    "W[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([-0.03207, -0.02283,  0.03549,  0.02813, -0.03413,  0.03188,\n",
       "       -0.03514, -0.00757, -0.01221,  0.04228, -0.04017, -0.00138,\n",
       "        0.04423,  0.0338 ,  0.04379, -0.04326,  0.04124, -0.0429 ,\n",
       "        0.02943,  0.03373,  0.00597,  0.02351,  0.03395,  0.00442,\n",
       "       -0.01538, -0.01041,  0.0054 ,  0.0008 ,  0.0071 , -0.04525],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_layer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([-0.00124,  0.02806,  0.01952,  0.01807, -0.01903,  0.02258,\n",
       "        0.03024, -0.04098, -0.02558, -0.00899, -0.01783, -0.04243,\n",
       "       -0.01648,  0.02209, -0.00038,  0.00113, -0.04222,  0.00695,\n",
       "        0.04144,  0.04491,  0.0142 ,  0.04779,  0.00758,  0.03593,\n",
       "       -0.02769, -0.02174,  0.02441, -0.00663,  0.01617, -0.03903],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_layer(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Item Embedding, User Embedding 구하기\n",
    "\n",
    "Tensorflow Keras에서 Item Embedding의 값과 User Embedding의 값을 가져오는 것은 매우 간단합니다. 우리는 층의 연결을 통해 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Embedding 구하기\n",
    "\n",
    "이 때 주의해야 하는 것은 positive item과 negative item은 같은 임베딩 레이어에서 가져와야 합니다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_item_embedding = item_embedding_layer(pos_item_id)\n",
    "neg_item_embedding = item_embedding_layer(neg_item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'item_embedding/embedding_lookup/Identity_1:0' shape=(None, 31) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'item_embedding/embedding_lookup_1/Identity_1:0' shape=(None, 31) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_item_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Embedding 구하기\n",
    "\n",
    "유저 임베딩에서 우리는 마지막 임베딩에 1을 추가해주어야 합니다. 아이템 임베딩의 마지막 원소값 Bias를 추가하기 위함입니다.바로 아래와 같은 방식으로 유저 임베딩과 아이템 임베딩이 형성됩니다.\n",
    "\n",
    "$$\n",
    "U = [u_1, u_2, u_3, ..., u_{60}, 1] \\\\\n",
    "I = [i_1, i_2, i_3, ..., i_{60}, i_{bias}] \n",
    "$$\n",
    "\n",
    "Dot 연산으로 Bias 연산까지 같이 수행하기 위해 아래와 같이 코드를 작성하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "user_embedding = user_embedding_layer(user_id)\n",
    "one_embedding = K.ones_like(user_embedding[:,-1:])\n",
    "\n",
    "user_embedding = Concatenate()([user_embedding, one_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Score 계산하기\n",
    "\n",
    "우리는 고객이 본 아이템에 대한 Score와 고객이 보지 않은 아이템에 대한 Score의 차이가 극대화되도록 학습하게 됩니다. 이를 위해 BPR에서는 **Individual Probability**, 즉 고객이 본 아이템에 대해 보지 않은 아이템보다 선호할 확률을 구하게 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "pos_score = Dot(axes=(1,1))([user_embedding, pos_item_embedding])\n",
    "neg_score = Dot(axes=(1,1))([user_embedding, neg_item_embedding])\n",
    "\n",
    "diff_score = pos_score - neg_score\n",
    "\n",
    "probs = sigmoid(diff_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Personalized Ranking은 위의 확률이 100%가 되도록 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Model 구성하기\n",
    "\n",
    "입력값은 크게 세가지 `user_id`, `pos_item_id`,`neg_item_id`으로 나뉘어집니다. 그리고 출력값은 보지 않은 아이템에 대한 선호도보다 본 아이템에 대한 선호도가 높을 확률(`individual probability`)인 `probs`이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model([user_id, pos_item_id, neg_item_id], probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Regularization 적용하기\n",
    "\n",
    "Matrix Factoriation은 쉽게 Overfitting, 즉 학습 데이터에만 과적합되는 현상이 발생합니다. 이를 방지하기 위해 가장 기본적인 방법론 중 하나는 Weight Decay, 즉 weight의 값이 너무 커지지 않도록 방지하는 것입니다. 이를 위해 아래와 같이 Loss를 추가해주게 되면, weight가 어느정도 줄어드는 방향으로 모델이 학습하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_pos_item = pos_item_embedding**2\n",
    "l2_neg_item = neg_item_embedding**2\n",
    "l2_user = user_embedding**2\n",
    "l2_reg = 0.0001\n",
    "\n",
    "weight_decay = l2_reg * tf.reduce_sum(l2_pos_item + l2_neg_item + l2_user)\n",
    "\n",
    "model.add_loss(weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Model 컴파일하기\n",
    "\n",
    "이전 구현체인 `implicit`에서는 기본 `SGD`를 이용했지만, 여기에서는 최대한 빠르게 수렴시키기 위해 변형체인 `Adagrad`를 이용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "model.compile(Adagrad(1.), \n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습 데이터 구성하기\n",
    "\n",
    "우리가 가지고 있는 데이터는 고객이 특정 영화에 대해 몇점의 평점을 주었는지에 대한 데이터입니다. 우리는 고객이 평가하지 않은 영화에 대한 정보를 생성해서 Pair 단위로 모델을 학습해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 고객이 평가하지 않은, 구매하지 않은 영화군 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 평가한 영화목록 구성하기\n",
    "itemset_per_user = (\n",
    "    train_df\n",
    "    .groupby('user_id')\n",
    "    ['item_id']\n",
    "    .apply(frozenset)\n",
    ")\n",
    "\n",
    "total_items = set(train_df.item_id.unique())\n",
    "\n",
    "# 유저가 평가하지 않은 영화목록 구성하기\n",
    "notseen_itemset_per_user = total_items - itemset_per_user\n",
    "notseen_itemset_per_user = notseen_itemset_per_user.apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 학습 데이터 구성하기\n",
    "\n",
    "우리는 매 Epoch마다 본것과 보지 않은 것에 대한 쌍을 무작위로 추출합니다. 그리고 학습 데이터에서 출력값은 항상 1로 나와야 합니다.(보지 않은 것에 대한 본것의 확률 = 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPR\n",
    "######################################################################\n",
    "# def get_bpr_dataset(train_df, notseen_itemset_per_user):\n",
    "#     batch_train_df = train_df.copy()\n",
    "#     batch_train_df = batch_train_df.sample(frac=1)\n",
    "#     batch_train_df['negative_item'] = batch_train_df.user_id.apply(\n",
    "#         lambda x : random.choice(notseen_itemset_per_user[x]))\n",
    "#    \n",
    "#     X = {\n",
    "#         \"user\":batch_train_df['user_id'].values,\n",
    "#         \"positive_item\":batch_train_df['item_id'].values,\n",
    "#         \"negative_item\":batch_train_df['negative_item'].values\n",
    "#     }\n",
    "#     y = np.ones((len(batch_train_df),1))\n",
    "#    \n",
    "#     return X, y\n",
    "\n",
    "# WBPR\n",
    "######################################################################\n",
    "def get_bpr_dataset(train_df):\n",
    "    batch_train_df = train_df.copy()\n",
    "    batch_train_df = batch_train_df.sample(frac=1)\n",
    "\n",
    "#     itemset_per_user = batch_train_df.groupby('user_id').item_id.apply(frozenset)\n",
    "#     neg_samples = []\n",
    "#     for user_id in tqdm(batch_train_df.user_id, total=len(batch_train_df)):\n",
    "#         neg_sample = (\n",
    "#             batch_train_df\n",
    "#             .loc[~batch_train_df.item_id.isin(itemset_per_user[user_id]), 'item_id']\n",
    "#             .sample(1)\n",
    "#             .iloc[0]\n",
    "#         )\n",
    "#         neg_samples.append(neg_sample)\n",
    "#     batch_train_df['negative_item'] = neg_samples\n",
    "\n",
    "    batch_train_df['negative_item'] = batch_train_df.item_id.sample(frac=1).values\n",
    "    \n",
    "        \n",
    "    X = {\n",
    "        \"user\":batch_train_df['user_id'].values,\n",
    "        \"positive_item\":batch_train_df['item_id'].values,\n",
    "        \"negative_item\":batch_train_df['negative_item'].values\n",
    "    }\n",
    "    y = np.ones((len(batch_train_df),1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y = get_bpr_dataset(train_df, notseen_itemset_per_user)\n",
    "X,y = get_bpr_dataset(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 모델 학습하기\n",
    "\n",
    "epoch 10번에 걸쳐 모델을 학습시키도록 하겠습니다. 매 Epoch마다 새로운 학습 pair를 생성하도록 하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th\n",
      "1533/1533 - 1s - loss: 0.7085 - binary_accuracy: 0.4702\n",
      "2th\n",
      "1533/1533 - 1s - loss: 0.7070 - binary_accuracy: 0.4748\n",
      "3th\n",
      "1533/1533 - 1s - loss: 0.6958 - binary_accuracy: 0.5363\n",
      "4th\n",
      "1533/1533 - 1s - loss: 0.6555 - binary_accuracy: 0.6331\n",
      "5th\n",
      "1533/1533 - 1s - loss: 0.6162 - binary_accuracy: 0.6755\n",
      "6th\n",
      "1533/1533 - 1s - loss: 0.5930 - binary_accuracy: 0.6975\n",
      "7th\n",
      "1533/1533 - 1s - loss: 0.5776 - binary_accuracy: 0.7115\n",
      "8th\n",
      "1533/1533 - 1s - loss: 0.5666 - binary_accuracy: 0.7224\n",
      "9th\n",
      "1533/1533 - 1s - loss: 0.5568 - binary_accuracy: 0.7323\n",
      "10th\n",
      "1533/1533 - 1s - loss: 0.5499 - binary_accuracy: 0.7392\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "for i in range(1,epoch+1):\n",
    "    print(\"{}th\".format(i))\n",
    "    # X,y = get_bpr_dataset(train_df, notseen_itemset_per_user)\n",
    "    X,y = get_bpr_dataset(train_df)\n",
    "    model.fit(X, y, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 평가하기\n",
    "\n",
    "Hit Ratio를 계산하기 위해서 User, Item의 쌍 별로 Score가 얼마나 나왔는지를 계산해야 합니다. Score을 계산하는 것은 BPR 모델에서 Positive Score와 Negative Score를 계산하는 것으로 이루어집니다. 이부분을 떼어내어 새로 모델을 구성하도록 하겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Model([user_id,pos_item_id],pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit Ratio를 계산하기 위해서 우리는 본 영화에 대한 Score와 보지 않은 영화에 대한 Score를 계산해야 합니다. 이때 본 영화에 대한 Score가 보지 않은 영화에 대한 Score보다 높을수록 좋습니다. 보통 Top-10, 보지 않은 영화 100개 중 10번째 Score보다 높으면 올바르게 추론(Hit)했다고 계산합니다. 이에 따라 계산하면 아래와 같이 계산됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "943it [00:48, 19.26it/s]\n"
     ]
    }
   ],
   "source": [
    "hit = 0.\n",
    "for i, row in tqdm(hit_ratio_df.iterrows()):\n",
    "    user = np.array([row.user_id])\n",
    "    seens = np.array([row.item_id])\n",
    "    pos_scores = test_model.predict([user,seens])\n",
    "    pos_scores = pos_scores[0,0]\n",
    "    \n",
    "    not_seens = np.array(row.not_seen_list)\n",
    "    users = np.array([row.user_id]*len(not_seens))   \n",
    "    neg_scores = test_model.predict([users,not_seens])\n",
    "    \n",
    "    if pos_scores > np.sort(neg_scores.flatten())[-10]:\n",
    "        hit += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit ratio : 0.513\n"
     ]
    }
   ],
   "source": [
    "hit_ratio = hit / len(hit_ratio_df)        \n",
    "print(f\"hit ratio : {hit_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 이용하기\n",
    "\n",
    "Bayesian Personalized Ranking에서 학습된 임베딩 값들은 아래와 같은 방식으로 임베딩 값을 추출할 수 있습니다. 간단하게 어떻게 이용했는지를 복습해도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding_weight = (\n",
    "    model.get_layer('item_embedding').get_weights()[0])\n",
    "\n",
    "item_embedding_df = pd.DataFrame(item_embedding_weight)\n",
    "item_embedding_df = item_embedding_df[\n",
    "    item_embedding_df.index.isin(movies_df.item_id)]\n",
    "item_embedding_df.index = movies_df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Tales From the Crypt Presents: Demon Knight (1995)    1.803866\n",
       "Natural Born Killers (1994)                           1.803743\n",
       "Candyman (1992)                                       1.685850\n",
       "Copycat (1995)                                        1.671408\n",
       "Jaws 2 (1978)                                         1.564870\n",
       "Virtuosity (1995)                                     1.512189\n",
       "Demolition Man (1993)                                 1.510551\n",
       "Bad Boys (1995)                                       1.509586\n",
       "Nightmare on Elm Street, A (1984)                     1.476377\n",
       "Crow, The (1994)                                      1.475660\n",
       "dtype: float32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    item_embedding_df\n",
    "    .dot(item_embedding_df.loc['Copycat (1995)'])\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Demolition Man (1993)                   2.346600\n",
       "Cliffhanger (1993)                      2.256768\n",
       "Under Siege (1992)                      2.227391\n",
       "Die Hard: With a Vengeance (1995)       2.210665\n",
       "Young Guns II (1990)                    2.172642\n",
       "Three Musketeers, The (1993)            2.059460\n",
       "Die Hard 2 (1990)                       2.057950\n",
       "Under Siege 2: Dark Territory (1995)    2.054211\n",
       "Stargate (1994)                         2.044352\n",
       "Crow, The (1994)                        2.043220\n",
       "dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    item_embedding_df\n",
    "    .dot(item_embedding_df.loc['Die Hard 2 (1990)'])\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Good, The Bad and The Ugly, The (1966)                                         1.224539\n",
       "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)    1.108616\n",
       "Blade Runner (1982)                                                            0.981658\n",
       "Terminator, The (1984)                                                         0.981235\n",
       "Die Hard (1988)                                                                0.955278\n",
       "2001: A Space Odyssey (1968)                                                   0.934000\n",
       "Braveheart (1995)                                                              0.899696\n",
       "Glory (1989)                                                                   0.884793\n",
       "Gandhi (1982)                                                                  0.876719\n",
       "Monty Python and the Holy Grail (1974)                                         0.872174\n",
       "dtype: float32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    item_embedding_df\n",
    "    .dot(item_embedding_df.loc['Terminator, The (1984)'])\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style = \"background-image: url('https://pai-picture.s3.ap-northeast-2.amazonaws.com/PAI-Identity/PublicAI+Logo.png');background-repeat: no-repeat; background-position: right; background-size: 60px 40px; padding : 5px 70px 5px 5px;\">\n",
    "    Copyright(c) 2020 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SeonYoul Choi ( best10@publicai.co.kr )  last updated on 2020/06/22\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
